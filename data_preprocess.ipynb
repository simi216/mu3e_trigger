{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5ad3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "with uproot.open(\"mu3e_root_data/run42_bg.root\") as file:\n",
    "    sensor_positions = file[\"alignment/sensors\"].arrays(library=\"pd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f2650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ragged_csv_to_ndarray(file_name: str, delimiter: str = \",\", fill_value = -1, max_cols = 256, dtype = int) -> np.ndarray:\n",
    "    rows = []\n",
    "    row_lengths = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by the delimiter and strip whitespace\n",
    "            row = np.array([value.strip() for value in line.strip().split(delimiter) if value != ''], dtype=dtype)\n",
    "            # Ensure the row has at most max_cols elements\n",
    "            if len(row) > max_cols:\n",
    "                continue\n",
    "            rows.append(row)\n",
    "            row_lengths.append(len(row))\n",
    "    # Convert the list of rows to a 2D NumPy array\n",
    "    ragged_array = np.full((len(rows), max_cols), fill_value, dtype=dtype)\n",
    "    for i, row in enumerate(rows):\n",
    "        ragged_array[i, :len(row)] = row\n",
    "    return ragged_array\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reorder_nla(nla: np.ndarray, padding_value: int = -1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reorders the NLA array to ensure that non-padded entries are at the beginning.\n",
    "    Assumes padding is identifiable via `nla[:, :, 0] == padding_value`.\n",
    "    \"\"\"\n",
    "    # Identify valid entries\n",
    "    valid_mask = nla[:, :, 0] != padding_value\n",
    "\n",
    "    # Compute number of valid entries per batch\n",
    "    counts = valid_mask.sum(axis=1)\n",
    "\n",
    "    # Flatten for easier fancy indexing\n",
    "    B, N, D = nla.shape\n",
    "    flat_nla = nla.reshape(B * N, D)\n",
    "    flat_valid_mask = valid_mask.reshape(B * N)\n",
    "\n",
    "    # Get indices of valid entries\n",
    "    valid_indices = np.nonzero(flat_valid_mask)[0]\n",
    "\n",
    "    # Allocate output\n",
    "    reordered_nla = np.full_like(nla, padding_value)\n",
    "\n",
    "    # Fill output using advanced indexing\n",
    "    row_ids = np.repeat(np.arange(B), counts)\n",
    "    group_counts = np.bincount(row_ids, minlength=B)\n",
    "\n",
    "    # Compute start indices for placing data\n",
    "    start_idx = np.zeros_like(group_counts)\n",
    "    np.cumsum(group_counts[:-1], out=start_idx[1:])\n",
    "\n",
    "    # Where to write valid entries in each row\n",
    "    insert_pos = np.hstack([np.arange(c) for c in group_counts])\n",
    "    reordered_nla[row_ids, insert_pos] = flat_nla[valid_indices]\n",
    "\n",
    "    return reordered_nla\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302982db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pid_to_location(pixel_id: np.ndarray, sensor_positions : pd.DataFrame, padding_value: float = -1, sensor_fault_rate = 0) -> np.ndarray:\n",
    "    if sensor_positions[\"id\"].empty:\n",
    "        raise ValueError(\"sensor_positions DataFrame is empty. Please load the sensor positions data first.\")\n",
    "    if sensor_positions[\"vx\"].empty or sensor_positions[\"vy\"].empty or sensor_positions[\"vz\"].empty:\n",
    "        raise ValueError(\"sensor_positions DataFrame does not contain position columns (vx, vy, vz).\")\n",
    "    if sensor_positions[\"rowx\"].empty or sensor_positions[\"rowy\"].empty or sensor_positions[\"rowz\"].empty:\n",
    "        raise ValueError(\"sensor_positions DataFrame does not contain row columns (rowx, rowy, rowz).\")\n",
    "    if sensor_positions[\"colx\"].empty or sensor_positions[\"coly\"].empty or sensor_positions[\"colz\"].empty:\n",
    "        raise ValueError(\"sensor_positions DataFrame does not contain column columns (colx, coly, colz).\")\n",
    "    sensor_positions = sensor_positions.set_index(\"id\", drop=False)\n",
    "    hit_chip_id =  pixel_id // 2**16\n",
    "    hit_col_id = (pixel_id // 2**8) % 2**8\n",
    "    hit_row_id = pixel_id % 2**8\n",
    "    location = np.full((*pixel_id.shape, 3), padding_value, dtype=np.float64)\n",
    "    for sensor_id_iter in range(sensor_positions.shape[0]):\n",
    "        if np.random.rand() < sensor_fault_rate:\n",
    "            continue\n",
    "        sensor_id = sensor_positions[\"id\"].iloc[sensor_id_iter]\n",
    "        if sensor_id // 2**12 != 0:\n",
    "            continue\n",
    "        mask = hit_chip_id == sensor_id\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        location[mask, 0] = sensor_positions[\"vx\"].iloc[sensor_id_iter] + (sensor_positions[\"rowx\"].iloc[sensor_id_iter] + 0.5)* hit_row_id[mask] + (sensor_positions[\"colx\"].iloc[sensor_id_iter] + 0.5) * hit_col_id[mask]\n",
    "        location[mask, 1] = sensor_positions[\"vy\"].iloc[sensor_id_iter] + (sensor_positions[\"rowy\"].iloc[sensor_id_iter] + 0.5)* hit_row_id[mask] + (sensor_positions[\"coly\"].iloc[sensor_id_iter] + 0.5) * hit_col_id[mask]\n",
    "        location[mask, 2] = sensor_positions[\"vz\"].iloc[sensor_id_iter] + (sensor_positions[\"rowz\"].iloc[sensor_id_iter] + 0.5)* hit_row_id[mask] + (sensor_positions[\"colz\"].iloc[sensor_id_iter] + 0.5) * hit_col_id[mask]\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e9894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"mu3e_trigger_data\"\n",
    "SIGNAL_DATA_FILE = f\"{DATA_DIR}/run42_sig.csv\"\n",
    "BACKGROUND_DATA_FILE = f\"{DATA_DIR}/run42_bg.csv\"\n",
    "\n",
    "bg_data = load_ragged_csv_to_ndarray(BACKGROUND_DATA_FILE, delimiter=\",\", fill_value=-1, max_cols=256, dtype=int)\n",
    "sig_data = load_ragged_csv_to_ndarray(SIGNAL_DATA_FILE, delimiter=\",\", fill_value=-1, max_cols=256, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5d68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_number = ((bg_data // 2**16 // 2**12) == 0).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe20e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data_positions = convert_pid_to_location(bg_data, sensor_positions, padding_value=-1)\n",
    "sig_data_positions = convert_pid_to_location(sig_data, sensor_positions, padding_value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f594b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data_positions = reorder_nla(bg_data_positions, padding_value=-1)\n",
    "sig_data_positions = reorder_nla(sig_data_positions, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fff982",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{DATA_DIR}/run42_bg_positions.npy\", bg_data_positions)\n",
    "np.save(f\"{DATA_DIR}/run42_sig_positions.npy\", sig_data_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a70c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pixel_id_to_nla(pixel_id: np.ndarray, padding_value: int = -1) -> np.ndarray:\n",
    "    nla = np.full((*pixel_id.shape, 4), padding_value, dtype=np.int32)\n",
    "    valid_mask = pixel_id != padding_value\n",
    "\n",
    "    chip_id = pixel_id // 2**16\n",
    "    station = chip_id // 2**12\n",
    "    layer = ((chip_id // 2**10) % 4) + 1\n",
    "    phi = ((chip_id // 2**5) % 2**5) + 1\n",
    "    z_prime = chip_id % 2**5\n",
    "\n",
    "    z = np.where(layer == 3, z_prime - 7, np.where(layer == 4, z_prime - 6, z_prime))\n",
    "\n",
    "    station_mask = (station == 0)\n",
    "    valid_mask = valid_mask & station_mask\n",
    "\n",
    "    nla[valid_mask, 0] = station[valid_mask]\n",
    "    nla[valid_mask, 1] = layer[valid_mask]\n",
    "    nla[valid_mask, 2] = phi[valid_mask]\n",
    "    nla[valid_mask, 3] = z[valid_mask]\n",
    "\n",
    "    return nla\n",
    "\n",
    "def reorder_nla(nla: np.ndarray, padding_value: int = -1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reorders the NLA array to ensure, that the non-padded entries are at the beginning of the array.\n",
    "    \"\"\"\n",
    "    reordered_nla = np.full_like(nla, padding_value, dtype=nla.dtype)\n",
    "    valid_mask = nla[:, :, 0] != padding_value\n",
    "    for i in range(nla.shape[0]):\n",
    "        valid_entries = nla[i, valid_mask[i]]\n",
    "        if valid_entries.size > 0:\n",
    "            reordered_nla[i, :valid_entries.shape[0]] = valid_entries\n",
    "\n",
    "    return reordered_nla\n",
    "\n",
    "\n",
    "def convert_nla_to_location(nla: np.ndarray, padding_value: float = -1) -> np.ndarray:\n",
    "    location = np.full((*nla.shape[:-1], 3), padding_value, dtype=np.float64)\n",
    "    layer = nla[:, : , 1]\n",
    "    phi = nla[:, : , 2]\n",
    "    z = nla[:, : , 3]\n",
    "    #### Define the paramters of the detector layers\n",
    "    r_layer_1 = 23.3\n",
    "    r_layer_2 = 29.8\n",
    "    r_layer_3 = 73.9\n",
    "    r_layer_4 = 86.3\n",
    "    length_layer_1 = 124.7\n",
    "    length_layer_2 = 124.7\n",
    "    length_layer_3 = 351.9\n",
    "    length_layer_4 = 372.6\n",
    "    nz_layer_1 = 6\n",
    "    nz_layer_2 = 6\n",
    "    nz_layer_3 = 17\n",
    "    nz_layer_4 = 18\n",
    "\n",
    "    nphi_layer_1 = 8\n",
    "    nphi_layer_2 = 10\n",
    "    nphi_layer_3 = 24\n",
    "    nphi_layer_4 = 28\n",
    "\n",
    "    #### Calculate the z-coordinate in the detector\n",
    "    location[layer == 1, 2] = ((z[layer == 1])/ nz_layer_1 - 0.5 ) * length_layer_1\n",
    "    location[layer == 2, 2] = ((z[layer == 2])/ nz_layer_2 - 0.5 ) * length_layer_2\n",
    "    location[layer == 3, 2] = ((z[layer == 3])/ nz_layer_3 - 0.5 ) * length_layer_3\n",
    "    location[layer == 4, 2] = ((z[layer == 4])/ nz_layer_4 - 0.5 ) * length_layer_4\n",
    "\n",
    "    #### Calculate the x-coordinate in the detector\n",
    "    location[layer == 1, 0] = r_layer_1 * np.cos((phi[layer == 1]) / nphi_layer_1 * 2 * np.pi)\n",
    "    location[layer == 2, 0] = r_layer_2 * np.cos((phi[layer == 2]) / nphi_layer_2 * 2 * np.pi)\n",
    "    location[layer == 3, 0] = r_layer_3 * np.cos((phi[layer == 3]) / nphi_layer_3 * 2 * np.pi)\n",
    "    location[layer == 4, 0] = r_layer_4 * np.cos((phi[layer == 4]) / nphi_layer_4 * 2 * np.pi)\n",
    "\n",
    "    #### Calculate the y-coordinate in the detector\n",
    "    location[layer == 1, 1] = r_layer_1 * np.sin((phi[layer == 1]) / nphi_layer_1 * 2 * np.pi)\n",
    "    location[layer == 2, 1] = r_layer_2 * np.sin((phi[layer == 2]) / nphi_layer_2 * 2 * np.pi)\n",
    "    location[layer == 3, 1] = r_layer_3 * np.sin((phi[layer == 3]) / nphi_layer_3 * 2 * np.pi)\n",
    "    location[layer == 4, 1] = r_layer_4 * np.sin((phi[layer == 4]) / nphi_layer_4 * 2 * np.pi)\n",
    "\n",
    "    return location\n",
    "\n",
    "\n",
    "def load_ragged_csv_to_ndarray(file_name: str, delimiter: str = \",\", fill_value = -1, max_cols = 256, dtype = int) -> np.ndarray:\n",
    "    rows = []\n",
    "    row_lengths = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by the delimiter and strip whitespace\n",
    "            row = np.array([value.strip() for value in line.strip().split(delimiter) if value != ''], dtype=dtype)\n",
    "            # Ensure the row has at most max_cols elements\n",
    "            if len(row) > max_cols:\n",
    "                continue\n",
    "            rows.append(row)\n",
    "            row_lengths.append(len(row))\n",
    "    # Convert the list of rows to a 2D NumPy array\n",
    "    ragged_array = np.full((len(rows), max_cols), fill_value, dtype=dtype)\n",
    "    for i, row in enumerate(rows):\n",
    "        ragged_array[i, :len(row)] = row\n",
    "    return ragged_array\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mu3e_trigger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
